# Special Topics in Statistical Learning

Advanced topics course at UATX.

Our primary book will be: [Introduction to Statistical Learning](https://www.statlearning.com).  A more advanced version of this book is [Elements of Statistical Learning](https://hastie.su.domains/ElemStatLearn/).  A secondary book on numerical optimization is [Numerical Optimization](https://www.math.uci.edu/~qnie/Publications/NumericalOptimization.pdf).

## Exercises

Please complete and be prepared to present solutions to the following [exercises](exercises/ex1.pdf).

Please read Chapter 2 of [Numerical Optimization](https://www.math.uci.edu/~qnie/Publications/NumericalOptimization.pdf).  You should come away with a good general understanding of two methods for optimizing smooth functions:  
1) the method of steepest descent, or simply _gradient descent_, and   
2) Newton's method.  

Feel free to skip the stuff about trust-region methods.  The overview of quasi-Newton methods is nice, but optional for now.  
